apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: raw-to-bronze-{{ params.stream }}-{{ ts_nodash }}
  namespace: {{ params.namespace }}
spec:
  type: Python
  mode: cluster
  sparkVersion: "4.0.1"
  image: {{ params.image }}
  imagePullPolicy: {{ params.image_pull_policy }}
  imagePullSecrets:
    - ghcr-pull
  mainApplicationFile: local:///opt/spark/app/raw_to_bronze_etl.py
  arguments:
    - --tables
    - "{{ params.tables }}"
    - --table-config
    - '{{ params.table_config | tojson }}'
    - --groups-config
    - '{{ params.groups_config | tojson }}'
    - --schema
    - {{ params.schema }}
    - --run-date
    - "{{ ds }}"
    - --mode
    - "{{ params.mode }}"
    - --partition-key
    - "{{ params.partition_key }}"
    - --event-date-column
    - "{{ params.event_date_column }}"
    - --lookback-days
    - "{{ params.lookback_days }}"
    - --raw-bucket
    - {{ params.raw_bucket }}
    - --raw-prefix
    - {{ params.raw_prefix }}
    - --bronze-bucket
    - {{ params.bronze_bucket }}
    - --bronze-prefix
    - {{ params.bronze_prefix }}
    - --source-system
    - {{ params.source_system }}
    - --app-name
    - {{ params.app_name }}
    - --image
    - {{ params.image }}
    - --init-registry
    - "{{ params.init_registry }}"
  sparkConf:
    spark.driver.extraClassPath: "/opt/spark/ivy/*"
    spark.executor.extraClassPath: "/opt/spark/ivy/*"
    spark.jars: "local:///opt/spark/ivy/hadoop-aws-3.4.2.jar,local:///opt/spark/ivy/hadoop-common-3.4.2.jar,local:///opt/spark/ivy/hadoop-client-runtime-3.4.2.jar,local:///opt/spark/ivy/hadoop-client-api-3.4.2.jar,local:///opt/spark/ivy/bundle-2.40.16.jar,local:///opt/spark/ivy/delta-spark_2.13-4.0.1.jar,local:///opt/spark/ivy/delta-storage-4.0.1.jar"
    spark.ui.enabled: "false"
    spark.sql.extensions: "io.delta.sql.DeltaSparkSessionExtension"
    spark.sql.catalog.spark_catalog: "org.apache.spark.sql.delta.catalog.DeltaCatalog"
    spark.hadoop.fs.s3a.endpoint: "{{ params.minio_endpoint }}"
    spark.hadoop.fs.s3a.path.style.access: "true"
    spark.hadoop.fs.s3a.connection.ssl.enabled: "{{ params.minio_ssl_enabled }}"
    spark.hadoop.fs.s3a.impl: "org.apache.hadoop.fs.s3a.S3AFileSystem"
  volumes:
    - name: ivy-cache
      persistentVolumeClaim:
        claimName: ivy-cache
  restartPolicy:
    type: Never
  driver:
    cores: {{ params.driver_cores }}
    coreRequest: "{{ params.driver_core_request }}"
    memory: "{{ params.driver_memory }}"
    serviceAccount: {{ params.service_account }}
    nodeSelector:
      kubernetes.io/hostname: ampere-k8s-node4
    volumeMounts:
      - name: ivy-cache
        mountPath: /opt/spark/ivy
    env:
      - name: MINIO_S3_ENDPOINT
        value: "{{ params.minio_endpoint }}"
      - name: MINIO_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: minio-creds
            key: MINIO_ACCESS_KEY
      - name: MINIO_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: minio-creds
            key: MINIO_SECRET_KEY
  executor:
    instances: {{ params.executor_instances }}
    cores: {{ params.executor_cores }}
    coreRequest: "{{ params.executor_core_request }}"
    memory: "{{ params.executor_memory }}"
    nodeSelector:
      kubernetes.io/hostname: ampere-k8s-node4
    volumeMounts:
      - name: ivy-cache
        mountPath: /opt/spark/ivy
    env:
      - name: MINIO_S3_ENDPOINT
        value: "{{ params.minio_endpoint }}"
      - name: MINIO_ACCESS_KEY
        valueFrom:
          secretKeyRef:
            name: minio-creds
            key: MINIO_ACCESS_KEY
      - name: MINIO_SECRET_KEY
        valueFrom:
          secretKeyRef:
            name: minio-creds
            key: MINIO_SECRET_KEY
